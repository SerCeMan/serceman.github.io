{"pageProps":{"source":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    code: \"code\",\n    img: \"img\",\n    h1: \"h1\",\n    a: \"a\",\n    span: \"span\",\n    h2: \"h2\",\n    pre: \"pre\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    em: \"em\",\n    h3: \"h3\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components), {Quote} = _components;\n  if (!Quote) _missingMdxReference(\"Quote\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Hi, folks!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Every single program allocates memory. Byte buffers are at the core of\\nmany essential libraries which power the services the modern internet is\\nbuilt upon. If you‚Äôre building such a library, or even just copying data\\nbetween different files, chances are you‚Äôll need to allocate a buffer.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In Java, \", _jsx(_components.code, {\n        children: \"ByteBuffer\"\n      }), \" is the class that allows you to do so. Once you‚Äôve\\ndecided to allocate a buffer, you‚Äôll be presented with two methods\\n\", _jsx(_components.code, {\n        children: \"allocate()\"\n      }), \" and \", _jsx(_components.code, {\n        children: \"allocateDirect()\"\n      }), \". Which one to use? The answer is, as\\nalways, it depends. If there were no tradeoffs, there wouldn‚Äôt be two\\nmethods. In this article, I‚Äôll explore some of these tradeoffs,\\ndemystify this behaviour, and I hope that the answer will be clear for\\nyou by the end of it.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/images/allocatedirect/itsgone.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(Quote, {\n      quote: \"Yeah well, sometimes the things we do don‚Äôt matter right now. Sometimes they matter later. We have to care more about later sometimes, you know.\",\n      attribution: \"Stan Marsh\"\n    }), \"\\n\", _jsxs(_components.h1, {\n      id: \"two-buffers\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#two-buffers\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Two buffers\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"At first glance, the two methods \", _jsx(_components.code, {\n        children: \"allocate()\"\n      }), \" and \", _jsx(_components.code, {\n        children: \"allocateDirect()\"\n      }), \" are\\nvery simple. The \", _jsx(_components.code, {\n        children: \"allocate()\"\n      }), \" allocates a buffer in the managed heap of\\nthe Java process, a part of this exact space which size is specified\\nwith the \", _jsx(_components.code, {\n        children: \"Xmx\"\n      }), \" option. The \", _jsx(_components.code, {\n        children: \"allocateDirect()\"\n      }), \" method allocates a buffer\\nresiding outside of the managed heap.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/images/allocatedirect/server3.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This difference, however, creates a number of significant runtime\\nimplications, which I‚Äôm going to dive into here. But first, let me start\\nby telling a debugging story where direct byte buffers were the\\nmurderer.\"\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"the-story\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#the-story\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"The story\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Every story needs a protagonist. In this case, the protagonist was a\\nJava application built on top of RSocket, a modern application protocol.\\nHere‚Äôs the oversimplified version of the app which you can find on\\n\", _jsx(_components.a, {\n        href: \"https://github.com/SerCeMan/allocatedirect/blob/master/src/main/java/me/serce/allocatedirect/Main.java\",\n        children: \"Github\"\n      }), \".\\nLet‚Äôs call this app an echo app. The echo code isn‚Äôt trying to do\\nanything complicated, it is a simple echo service built with an awesome\\n\", _jsx(_components.a, {\n        href: \"https://github.com/rsocket/rsocket-java\",\n        children: \"rsocket-java\"\n      }), \" library. All it\\ndoes is spins up a client and a server, where the client sends messages,\\nand the server echoes them back.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"var\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"server\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" RSocketServer.create(echo) \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"//...\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"var\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"client\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" RSocketConnector.create() \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"//...\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"true\"\n        }), \") {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"assert\"\n        }), \" Objects.equals(client.send(), client.receive())\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.table, {\n      children: _jsx(_components.thead, {\n        children: _jsxs(_components.tr, {\n          children: [_jsx(_components.th, {\n            children: \"‚ùóÔ∏è\"\n          }), _jsxs(_components.th, {\n            children: [\"The supporting code for this article is available \", _jsx(_components.a, {\n              href: \"https://github.com/SerCeMan/allocatedirect\",\n              children: \"on Github\"\n            }), \". You can, and I highly encourage you to, choose to go through each step yourself by cloning the code and running each example with a simple bash script. All measurements were taken on an EC2 AWS \", _jsx(_components.a, {\n              href: \"https://aws.amazon.com/ec2/instance-types/m5/\",\n              children: \"m5.large\"\n            }), \" instance. Unless specified otherwise, \", _jsx(_components.em, {\n              children: \"Java 13\"\n            }), \" is used. The point of this article is not to show the numbers but rather demonstrate the techniques that you can use to debug your own application.\"]\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The code is useless if it‚Äôs just sitting in the repo and doing nothing,\\nso let‚Äôs clone the repo and start the app.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-bash\",\n        children: [\"git \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"clone\"\n        }), \" https://github.com/SerCeMan/allocatedirect.git\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"cd\"\n        }), \" allocatedirect && ./start.sh\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The app starts, and you should see that the logs are flowing. As\\nexpected, now it‚Äôs processing a large number of messages. However, if\\nthe echo app was exposed to users, they would start noticing significant\\npauses every now and then. All Java developers know that the first thing\\nto look at in the case of spurious pauses is GC.\"\n    }), \"\\n\", _jsx(_components.table, {\n      children: _jsx(_components.thead, {\n        children: _jsxs(_components.tr, {\n          children: [_jsx(_components.th, {\n            children: \"‚ùóÔ∏è\"\n          }), _jsxs(_components.th, {\n            children: [\"You can find GC logs of the app are stored in \", _jsx(_components.code, {\n              children: \"/tmp/${gcname}\"\n            }), \". The example logs for each run are also available in the \", _jsx(_components.a, {\n              href: \"https://github.com/SerCeMan/allocatedirect/tree/master/logs\",\n              children: \"repo\"\n            }), \". In this article, gceasy.io was used for visualisation. It‚Äôs a great free online tool which supports the log format of multiple garbage collectors. Even though you can always visualise GC logs using a tool like gceasy, as we‚Äôll see later, the raw logs often contain a lot more information than most of the tools can display.\"]\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Indeed, GC logs show that GC is to blame here. The application is\\nrunning under G1, which is the default collector since JDK 9. There are\\nmultiple young GC pauses on the graph. Young GC is a stop-the-world\\npause in GC in G1. The application stops completely to perform a\\ncleanup. For the echo server, the graph shows multiple young GC pauses\\nthat last for 100-130ms and occur every 10 seconds.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"G1 GC\"\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/images/allocatedirect/g1before.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Luckily for us, in the last few years, there has been an amazing\\ndevelopment in the GC space. There are not just one but two new fully\\nconcurrent garbage collectors,\\n\", _jsx(_components.a, {\n        href: \"https://wiki.openjdk.java.net/display/zgc/Main\",\n        children: \"ZGC\"\n      }), \" and\\n\", _jsx(_components.a, {\n        href: \"https://wiki.openjdk.java.net/display/shenandoah/Main\",\n        children: \"Shenandoah\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"While I‚Äôve had \", _jsx(_components.a, {\n        href: \"https://twitter.com/SerCeMan/status/1246676501925224449\",\n        children: \"great\\nsuccess\"\n      }), \" with\\nZGC before, Shenandoah has a great advantage of being much friendlier to\\napplication memory consumption. Many applications, especially simple\\nJSON in, JSON out stateless services are not memory-constrained. Some\\napplication, on the other hand, especially the ones that process a large\\nnumber of connections might be very sensitive to memory usage.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Even though the echo app only has a single client and a server in its\\ncurrent state, it could as well handle tens of thousands of connections.\\nIt‚Äôs time to enable Shenandoah, and run the echo app again.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-bash\",\n        children: [\"./start.sh shen \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# starts with -XX:+UseShenandoahGC\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"After enabling Shenandoah, the GC logs start showing an interesting\\npicture. There is definitely a huge improvement in the pause frequency.\\nThe pauses now only occur every minute or so. However, the pauses are\\nstill around 90ms long, which is far away from the desired\\nsub-millisecond pauses.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"Shenandoah GC\"\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/images/allocatedirect/shenandoah.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that the symptoms are clear, and the problem is reproducible, it‚Äôs\\ntime to look at the cause. GC graphs don‚Äôt show much more information.\\nLooking at the raw logs directly, on the other hand, reveals the cause\\nwhich is clearly stated right on the pause line.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"\",\n        children: \"...\\n[info][gc] GC(15) Pause Final Mark (process weakrefs) 86.167ms\\n...\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Turns out, weak references are to blame. Put simply, weak references are\\na way to keep an object in memory until there is a demand for this\\nmemory. Large in-memory caches is a common use-case for weak references.\\nIf there is enough free heap, a weak reference cache entry can stay\\nthere. As soon as GC figures out that there is not enough memory, it‚Äôll\\ndeallocate weak references. In most of the cases, this is a much better\\noutcome than the application failing with an out of memory exception\\nbecause of a cache.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A frantic search across the repository doesn‚Äôt show any usages of weak,\\nsoft or phantom references. Not even the search through the third party\\nlibraries can show anything. After staring at the metrics for a while,\\none of the graphs gives a clue! The long GC pauses correlate with a\\nsudden drop in the number of direct byte buffers.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"GC vs DirectByteBuffer count\"\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/images/allocatedirect/jmc-gc.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.table, {\n      children: _jsx(_components.thead, {\n        children: _jsxs(_components.tr, {\n          children: [_jsx(_components.th, {\n            children: \"‚ùóÔ∏è\"\n          }), _jsxs(_components.th, {\n            children: [\"You can get a similar graph by running the echo app and connecting to the JMX port. For this screenshot, I used Java Mission Control (JMC). The \", _jsx(_components.a, {\n              href: \"https://github.com/SerCeMan/allocatedirect/blob/master/start.sh#L53\",\n              children: \"start.sh\"\n            }), \" script contains the options that you can enable to connect to an app with JMX remotely.\"]\n          })]\n        })\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"At first, the correlation might not make any sense. Byte buffers are not\\nweak references, are they? They are not weak references themselves.\\nHowever, you might notice, that creating a new direct byte buffer gives\\nyou back a plain \", _jsx(_components.code, {\n        children: \"ByteBuffer\"\n      }), \" interface which doesn‚Äôt have a \", _jsx(_components.code, {\n        children: \"close\"\n      }), \"\\nmethod or any other way of deallocating the buffer.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"ByteBuffer\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"buf\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" ByteBuffer.allocateDirect(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"42\"\n        }), \");\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The underlying buffer needs to go away once the last reference to this\\nbuffer goes away. The modern API for this in Java is\\n\", _jsx(_components.a, {\n        href: \"https://docs.oracle.com/en/java/javase/13/docs/api/java.base/java/lang/ref/Cleaner.html\",\n        children: _jsx(_components.code, {\n          children: \"java.lang.ref.Cleaner\"\n        })\n      }), \".\\nAs we can see, it‚Äôs exactly what \", _jsx(_components.code, {\n        children: \"DirectByteBuffer\"\n      }), \" class uses to\\ndetermine when the underlying buffer should be deallocated.\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsxs(_components.em, {\n          children: [_jsx(_components.a, {\n            href: \"https://github.com/openjdk/jdk13/blob/dcd4014cd8a6f49a564cbb95387ad01a80a20bed/src/java.base/share/classes/java/nio/Direct-X-Buffer.java.template#L113-L141\",\n            children: \"DirectByteBuffer\"\n          }), \"\\nconstructor\"]\n        })\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [\"DirectByteBuffer(\", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"int\"\n        }), \" cap) {\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// ...\"\n        }), \"\\n    base = UNSAFE.allocateMemory(size); \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// malloc call\"\n        }), \"\\n    UNSAFE.setMemory(base, size, (\", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"byte\"\n        }), \") \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \");\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// ...\"\n        }), \"\\n    cleaner = Cleaner.create(\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"this\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Deallocator\"\n        }), \"(base, size, cap));\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Yet, there are no usages of direct buffers in the code of the echo app\\neither, so how could we find them? One way would be to search through\\nthe third party libraries using IntelliJ. The approach would work very\\nwell for the echo example but would completely fail for any real\\napplications of a decent size. There are just way too many places where\\nbyte buffers are used. Looking at the graphs, one can notice that the\\nnumber of created buffers per minute is huge, literally millions of\\nthem.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Instead of searching through the code to find all byte buffer\\nreferences, it is easier to find the place at runtime. One way to find\\nout where the majority of the buffers is created is to fire up the async\\nprofiler and profile the\\n\", _jsx(_components.a, {\n        href: \"https://man7.org/linux/man-pages/man3/malloc.3.html\",\n        children: _jsx(_components.code, {\n          children: \"malloc\"\n        })\n      }), \" calls\\nwhich are used by direct buffers to allocate memory.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-bash\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# async profiler can be downloaded from https://github.com/jvm-profiling-tools/async-profiler\"\n        }), \"\\n./profiler.sh -d 30 -f /tmp/flamegraph.svg $(pgrep -f java) -e malloc\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While running, the profiler managed to sample more than 500000 malloc\\ncalls which non-ambiguously show where all of the buffers were created\\nfrom.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"malloc calls\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/mallocflame.svg\"\n    }), \"\\n\", _jsx(_components.table, {\n      children: _jsx(_components.thead, {\n        children: _jsxs(_components.tr, {\n          children: [_jsx(_components.th, {\n            children: \"‚ùóÔ∏è\"\n          }), _jsxs(_components.th, {\n            children: [\"The flame graph above visualises the code paths where most of the captured malloc calls occur. The wider the column is, the larger the number of times the code path appeared in the sample. This graph, as well as other flame graphs in this article, is clickable. You can read more on how to read flame graphs \", _jsx(_components.a, {\n              href: \"http://www.brendangregg.com/flamegraphs.html\",\n              children: \"here\"\n            }), \".\"]\n          })]\n        })\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"As it turned out, there was a place in the code which was using direct\\nbuffers. With this rich knowledge of where exactly the direct buffer\\nallocations occur, creating a fix is easy. All that‚Äôs needed is to make\\na one line change and to replace \", _jsx(_components.code, {\n        children: \"allocateDirect\"\n      }), \" with \", _jsx(_components.code, {\n        children: \"allocate\"\n      }), \" and\\nsend a \", _jsx(_components.a, {\n        href: \"https://github.com/rsocket/rsocket-java/pull/945\",\n        children: \"PR upstream\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Running the same app on shenandoah after applying the single line change\\nproduces a completely different graph which pleases the eyes with\\nsub-millisecond GC pauses.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"Shenandoah GC\"\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/images/allocatedirect/shenandoah-heap.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"the-costs\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#the-costs\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"The costs\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The story revealed a dark side of direct byte buffers. If there is a\\ndark side, there must be a bright side as well! There is. But before we\\nlook at the bright side, we need to explore a few more sides which also\\nappeared to be grey.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"allocations\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#allocations\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Allocations\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Previously, we‚Äôve observed implicit deallocations costs, so now it‚Äôs\\ntime to take a look at allocations. Could direct buffers be much cheaper\\nto create? After all, going off-heap has been a performance trend for a\\nwhile. A small benchmark can help to estimate the costs.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: _jsx(_components.a, {\n            href: \"https://github.com/SerCeMan/allocatedirect/blob/master/bench/src/main/java/me/serce/AllocateBuffer1.java\",\n            children: \"AllocationBenchmark.java\"\n          })\n        })\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Param({\\\"128\\\", \\\"1024\\\", \\\"16384\\\"})\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"int\"\n        }), \" size;\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Benchmark\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" ByteBuffer \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"heap\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"()\"\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" ByteBuffer.allocate(size);\\n}\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Benchmark\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" ByteBuffer \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"direct\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"()\"\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" ByteBuffer.allocateDirect(size);\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"After cloning the repo, you can run the benchmark yourself with the\\ncommand below.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-bash\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Don't just read! Clone the repo and try yourself! ü§ì\"\n        }), \"\\n./bench.sh alloc1\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The absolute numbers are not that interesting. Even the slowest\\noperation only takes a few microseconds. But the difference between the\\nheap buffers and direct buffers is fascinating.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-bash\",\n        children: \"Benchmark               (size)  Mode  Cnt     Score     Error  Units\\nAllocateBuffer1.direct     128  avgt    5  1022.137 ¬± 148.510  ns/op\\nAllocateBuffer1.heap       128  avgt    5    23.969 ¬±   0.051  ns/op\\n\\nAllocateBuffer1.direct    1024  avgt    5  1228.785 ¬± 127.090  ns/op\\nAllocateBuffer1.heap      1024  avgt    5   179.350 ¬±   2.989  ns/op\\n\\nAllocateBuffer1.direct   16384  avgt    5  3039.485 ¬± 111.714  ns/op\\nAllocateBuffer1.heap     16384  avgt    5  2620.722 ¬±   5.395  ns/op\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Even though direct buffers lose in all of the runs, the difference is\\nmuch more noticeable on small buffers while on large buffers, the\\noverhead is almost negligible. Due to the 50x difference on a small\\nbuffer, it‚Äôs a much more compelling example to look into. Let‚Äôs start a\\nbenchmark again, make it run for much longer, and use async profiler to\\nsee what where the time is spent.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"ByteBuffer.allocateDirect()\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/alloc_direct_perf.svg\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The flame graph already hints towards some of the overhead. Not only the\\ndirect buffers need to allocate memory, but it also needs to reserve it\\nto check the maximum native memory limit. On top of this, the buffer\\nneeds to be zeroed as \", _jsx(_components.code, {\n        children: \"malloc\"\n      }), \" can‚Äôt guarantee that it doesn‚Äôt return\\nyou some garbage while the buffer needs to be ready to use. And finally,\\nit needs to register itself for deallocation as a soft reference. All of\\nthis seems like a lot of work, but the actual allocation still takes a\\nhalf of the time! So, even if the heap buffer doesn‚Äôt need to do any\\nwork other than calling \", _jsx(_components.code, {\n        children: \"malloc\"\n      }), \", it should only be as twice as slow,\\nnot 50 times! Profiling heap buffer allocations can hopefully reveal\\nwhere such a vast difference is coming from.\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"ByteBuffer.allocate()\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/alloc_heap_perf.svg\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The heap buffer flame graph is surprisingly blank. There isn‚Äôt much\\nhappening on the graph. Yet, there are still some allocations in the\\nyellow flame tower on the right. However, the whole allocation path only\\ntakes 2% of the time, and the rest is nothing? Exploring the yellow\\ntower gives a further clue. Most of its time is taken by a function\\nthat‚Äôs called \", _jsx(_components.code, {\n        children: \"MemAllocator::allocate_inside_tlab_slow\"\n      }), \". The meaning of\\nthe \", _jsx(_components.code, {\n        children: \"allocate_slow\"\n      }), \" part is self-explanatory, but it‚Äôs \", _jsx(_components.code, {\n        children: \"inside_tlab\"\n      }), \"\\nthat is the answer.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"TLAB stands for Thread Local Allocation Buffer. TLAB is a space in the\\nEden, the space where all new objects are born, dedicated for each\\nthread to allocate objects. When different threads allocate memory, they\\ndon‚Äôt have to contend on the global memory. Every thread allocates\\nobjects locally, and because the buffer is not shared with other\\nthreads, there is no need to use call \", _jsx(_components.code, {\n        children: \"malloc\"\n      }), \". All that‚Äôs needed is to\\nmove the pointer by a few bytes. The fact that most of the allocations\\nhappen in TLAB could explain why heap buffers are so much faster when\\ntheir size is small. When the size is large, the allocations won‚Äôt occur\\nin TLAB due to the limits on its size, which will result in buffer\\nallocation times being almost on par.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we‚Äôve assumed that we know why it‚Äôs so much faster, can we jump\\nto the next section? Not so fast!\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"So far, TLAB is just a theory, and we need to conduct an experiment to\\nvalidate it. One of the easiest ways is to simply disable TLAB with the\\n\", _jsx(_components.code, {\n        children: \"-XX:-UseTLAB\"\n      }), \" options.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// run with ./bench.sh alloc4\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Fork(jvmArgsAppend = { \\\"-XX:-UseTLAB\\\" })\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Benchmark\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" ByteBuffer \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"heap\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"()\"\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" ByteBuffer.allocate(size);\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"\",\n        children: \"Benchmark             (size)  Mode  Cnt    Score   Error  Units\\nAllocateBuffer2.heap     128  avgt    5  151.999 ¬± 8.477  ns/op\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Were we right? Yes and no. The performance results with disabled TLAB\\nare not as impressive anymore. Though, the pure allocation time is still\\nabout three times faster even considering that the benchmark needs to\\nnot only allocate memory for the buffer itself but also for the\\n\", _jsx(_components.code, {\n        children: \"ByteBuffer\"\n      }), \" class. The still significant difference shows the cost of\\ngoing back to the operating system with a syscall every time to ask for\\nmore memory with occasional page faults.\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"ByteBuffer.allocate(), -XX:-UseTLAB\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/alloc_heap_no_tlab.svg\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"As a rule of thumb, if your buffers are mostly short-lived and small,\\nusing heap byte buffers will likely be a more performant choice for you.\\nConveniently, it‚Äôs exactly what the javadoc of the ByteBuffer class is\\nwarning us about.\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"It is therefore recommended that direct buffers be allocated primarily\\nfor large, long-lived buffers that are subject to the underlying\\nsystem‚Äôs native I/O operations.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"‚Äî  ByteBuffer.java\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.h4, {\n      id: \"memory-costs\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#memory-costs\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Memory costs\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"So far, we‚Äôve only been measuring allocations. Still, looking at the\\nflame graphs, we can also see the de-allocation path which is frequently\\ninvoked by JMH that runs the benchmarks by explicitly invoking\\n\", _jsx(_components.a, {\n        href: \"https://github.com/openjdk/jmh/blob/4264de9486c32b48da8161e3ac076a0187b4176f/jmh-core/src/main/java/org/openjdk/jmh/runner/BaseRunner.java#L273\",\n        children: _jsx(_components.code, {\n          children: \"System.gc()\"\n        })\n      }), \"\\nand finalization before each iteration. That way, the previously\\nallocated buffers will be deallocated.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"However, in the real applications, as we saw in the debugging story,\\nwe‚Äôre at a mercy of the GC to deallocate those buffers. In this case,\\nthe amount of memory consumed by the app might be hard to predict as it\\ndepends on the GC and how the GC behaves on this workload. For how long\\nwould the following code run?\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"class\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"HeapMemoryChaser\"\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"static\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"void\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"main\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"(String[] args)\"\n        }), \" {\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"true\"\n        }), \") {\\n      ByteBuffer.allocate(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1024\"\n        }), \");\\n    }\\n  }\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The code above contains an infinite loop, so you can say forever, and\\nyou will be completely right. There are no conditions, so there is\\nnothing that can prevent the loop from running. Will this snippet run\\nforever too?\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"class\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"DirectMemoryChaser\"\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"static\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"void\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"main\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"(String[] args)\"\n        }), \" {\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"true\"\n        }), \") {\\n      ByteBuffer.allocateDirect(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1024\"\n        }), \");\\n    }\\n  }\\n}\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Will the above code run forever as well? It depends on how lucky we are.\\nThere are no guarantees on when a GC would clean up the allocated direct\\nbuffers. Various JVM options can vary the result from run forever with\\nno issues to a crash after a few seconds. Running the above code with\\n\", _jsx(_components.code, {\n        children: \"-Xmx6G\"\n      }), \" on a VM with 8GB RAM runs for about 20 seconds until it gets\\nkilled by the operating system.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"\",\n        children: \"$ time java -Xmx6G DirectMemoryChaser\\nKilled\\n\\nreal    0m24.211s\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"dmesg\"\n      }), \" shows an insightful message explaining that the process was\\nkilled due to lack of memory.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"\",\n        children: \"[...] Out of memory: Killed process 4560 (java) total-vm:10119088kB, anon-rss:7624780kB, file-rss:1336kB, shmem-rss:0kB, UID:1000 pgtables:15216kB oom_score_adj:0\\n[...] oom_reaper: reaped process 4560 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Allocating direct buffers without care can cause the app to go far\\nbeyond the expected memory usage as there are no guarantees on when the\\nsoft references are going to be cleaned. Crashing right after the start\\nis counterintuitively a good result. At least, you can observe the\\nfailure, reproduce it, understand it and fix it. A crash after a few\\nhours of running is much worse, and without a clear feedback loop, it‚Äôs\\nmuch harder to resolve the issue.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"When debugging such issues, or as a preventative measure, consider using\\n\", _jsx(_components.code, {\n        children: \"-XX:+AlwaysPreTouch\"\n      }), \" to at least exclude the heap growth out of the\\nequation. One way to prevent this is to run the infinite growth of\\ndirect buffers is to use \", _jsx(_components.code, {\n        children: \"-XX:MaxDirectMemorySize=${MAX_DIRECT_MEM}\"\n      }), \" to\\nensure that the usage of direct memory doesn‚Äôt grow uncontrollably.\"]\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"the-benefits\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#the-benefits\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"The benefits\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So far, the direct byte buffers have only caused troubles. In the story,\\nswitching to heap-based byte buffers was a clear win, though there are a\\nlot of hidden dangers in using them. Would it be reasonable to use heap\\nbyte buffers only and never use direct buffers? The choice exists for a\\nreason, and there reasons to use direct buffers.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"off-heap-graal\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#off-heap-graal\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Off Heap Graal\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We have observed problems with allocations and deallocations, so what if\\na buffer is only allocated once and never deallocated? One buffer is not\\nenough most of the time, so you can create a pool of buffers, borrow\\nthem for some time and then return back. It is what Netty does with\\ntheir \", _jsx(_components.a, {\n        href: \"https://netty.io/wiki/using-as-a-generic-library.html\",\n        children: _jsx(_components.code, {\n          children: \"ByteBuf\"\n        })\n      }), \"\\nclasses which are built to fix some of the downsides of the \", _jsx(_components.code, {\n        children: \"ByteBuffer\"\n      }), \"\\nclass. Nevertheless, it‚Äôs still not clear why one should prefer direct\\nbuffers over heap buffers.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Avoiding GC altogether could be one of the reason. You could be managing\\nterabytes of memory without any GC overhead. While you could manage\\nlarge amounts of memory with direct byte buffers, there is a limit of\\n2^31 on the indices that you can use with a single buffer. A solution is\\ncoming in the form of a \", _jsx(_components.a, {\n        href: \"https://openjdk.java.net/jeps/383\",\n        children: \"Foreign-Memory Access\\nAPI\"\n      }), \" which is available for the\\nsecond preview in JDK 15. But avoiding GC is not the main reason.\"]\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"io\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#io\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"IO\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The IO is where direct byte buffers shine! Let‚Äôs say we need to copy\\nsome memory between two files. Heap byte buffers are obviously backed by\\nmemory in a heap, so the contents of the files would have to be copied\\nto be sent back seconds later. This can be avoided completely with\\ndirect byte buffers. Direct byte buffers excel when you don‚Äôt need a\\nbuffer per se but rather a pointer to a piece of memory somewhere\\noutside of the heap. Again, at this point, this is only a hypothesis of\\na random person on the internet. Let‚Äôs prove or disprove it with the\\nfollowing benchmark.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: _jsx(_components.a, {\n            href: \"https://github.com/SerCeMan/allocatedirect/blob/master/bench/src/main/java/me/serce/CopyFileBenchmark.java\",\n            children: \"CopyFileBenchmark.java\"\n          })\n        })\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Benchmark\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// ./bench.sh reverse\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"void\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"reverseBytesInFiles\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"()\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"throws\"\n        }), \" Exception {\\n  \", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"ByteBuffer\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"buf\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"this\"\n        }), \".buffer;\\n  buf.clear();\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"try\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"FileChannel\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"channel1\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" FileChannel.open(Paths.get(DIR + \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"file1\\\"\"\n        }), \"), READ);\\n       \", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"FileChannel\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"channel2\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" FileChannel.open(Paths.get(DIR + \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"file2\\\"\"\n        }), \"), WRITE)) {\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (buf.hasRemaining()) {\\n      channel1.read(buf);\\n    }\\n    buf.put(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \", buf.get(SIZE - \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \"));\\n    buf.flip();\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (buf.hasRemaining()) {\\n      channel2.write(buf);\\n    }\\n  }\\n}\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The code above reads 64 MB of random data from the first files, reverses\\nthe byte order of each long in the array and then puts it back.\\nReversing the first and the last bytes here is a tiny operation which\\nthe only goal is to modify the contents of the file in some way as\\ncopying could simply be done by calling \", _jsx(_components.code, {\n        children: \"channel.transferTo\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The results show that the direct buffer is the clear winner, almost\\ntwice as fast!\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"\",\n        children: \"Benchmark                              (bufferType)  Mode  Cnt   Score   Error  Units\\nCopyFileBenchmark.reverseBytesInFiles        direct  avgt    5  36.383 ¬± 0.683  ms/op\\nCopyFileBenchmark.reverseBytesInFiles          heap  avgt    5  59.816 ¬± 0.834  ms/op\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The next step is to understand where the time was spent to validate our\\nhypothesis. Taking a flamegraph for the direct buffer shows what we\\nexpected ‚Äî all of the time spent in kernel reading and writing files.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"Directy Buffer\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/reverse_offheap.svg\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For the heap buffer, for both operations, reading and writing, the\\nmemory has to be copied first between the buffers which we can clearly\\nsee from the flamegraph. A solid chunk of it is taken by the\\n\", _jsx(_components.code, {\n        children: \"copyMemory\"\n      }), \" function.\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"Heap Buffer\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/reverse_heap.svg\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The IO here does not only refer to writing to disk, but it can also be\\nwriting to a socket which is what a considerable portion of the java\\napplications is performing all day non-stop. As you can see, carefully\\nchoosing your buffers can significantly affect performance.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"endianness\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#endianness\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Endianness\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Can direct byte buffers be even faster? While reading the javadoc for\\ncreate methods, note an important remark:\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"The new buffer‚Äôs position will be zero, its limit will be its\\ncapacity, its mark will be undefined, each of its elements will be\\ninitialized to zero, and its byte order will be ByteOrder#BIG_ENDIAN.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"‚Äî  ByteBuffer.java\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The byte order of byte buffers created in java is always big endian by\\ndefault. While having an always predictable default is great, it also\\nmeans that sometimes, it might not match the endianness of the\\nunderlying platform. In the case of an \", _jsx(_components.code, {\n        children: \"m5.large\"\n      }), \" AWS instance, this is\\nindeed the case.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-shell\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-meta prompt_\",\n          children: \"jshell> \"\n        }), _jsx(_components.span, {\n          className: \"bash\",\n          children: \"java.nio.ByteOrder.nativeOrder()\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-meta prompt_\",\n          children: \"$\"\n        }), _jsx(_components.span, {\n          className: \"bash\",\n          children: \"1 ==> LITTLE_ENDIAN\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This fact immediately raises the question if, or rather when changing\\nendianness can yield any significant performance wins. The only way to\\nfind out is to measure it.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: _jsx(_components.a, {\n            href: \"https://github.com/SerCeMan/allocatedirect/blob/master/bench/src/main/java/me/serce/OrderBenchmark.java\",\n            children: \"OrderBenchmark.java\"\n          })\n        })\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-java\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"static\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"final\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"int\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"SIZE\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1024\"\n        }), \" * \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1024\"\n        }), \" * \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1024\"\n        }), \";\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Param({\\\"direct-native-order\\\", \\\"direct\\\"})\"\n        }), \"\\nString bufferType;\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Setup\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"void\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"setUp\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"()\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"throws\"\n        }), \" Exception {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"switch\"\n        }), \" (bufferType) {\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"case\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"direct\\\"\"\n        }), \":\\n      buffer = ByteBuffer.allocateDirect(SIZE); \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"break\"\n        }), \";\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"case\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"direct-native-order\\\"\"\n        }), \":\\n      buffer = ByteBuffer.allocateDirect(SIZE).order(ByteOrder.nativeOrder()); \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"break\"\n        }), \";\\n  }\\n  channel = FileChannel.open(Paths.get(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"/dev/urandom\\\"\"\n        }), \"), READ);\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (buffer.hasRemaining()) { channel.read(buffer); }\\n  buffer.flip();\\n  \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"this\"\n        }), \".buffer = buffer.asLongBuffer();\\n}\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-meta\",\n          children: \"@Benchmark\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// run with ./bench.sh order\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"public\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"long\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"sumBytes\"\n        }), _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"()\"\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"long\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"sum\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \";\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-type\",\n          children: \"int\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable\",\n          children: \"i\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"; i < SIZE / \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"8\"\n        }), \"; i++) {\\n    sum += buffer.get(i);\\n  }\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" sum;\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The above benchmark measures a specific use-case. We load a gigabyte\\nworth of random longs into memory. Then, we simply read them one by one.\\nIt‚Äôs interesting that depending on the endianness, the result will be\\ndifferent as it affects the order of the bytes. We don‚Äôt care about the\\nbyte order for this use-case, however, as a random value with reversed\\nbyte order is still a random value.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"\",\n        children: \"Benchmark                       (bufferType)  Mode  Cnt    Score   Error  Units\\nOrderBenchmark.sumBytes  direct-native-order  avgt    5  136.025 ¬± 2.262  ms/op\\nOrderBenchmark.sumBytes               direct  avgt    5  195.980 ¬± 8.360  ms/op\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The first impression is that iterating through a gigabyte worth of\\nrandom memory is pretty darn fast. The second is that the native order\\nbyte buffer is performing 1.5 times faster! As before, running async\\nprofiler helps to reveal the reason why the native order is more\\nperformant.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"Non-native (Big Endian)\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/sum_big_endian.svg\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"formalpara-title\",\n      children: _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: \"Native (Little Endian)\"\n        })\n      })\n    }), \"\\n\", _jsx(\"object\", {\n      type: \"image/svg+xml\",\n      data: \"/images/allocatedirect/sum_native_endian.svg\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Comparing the graphs above, the first difference that stands out is that\\nbyte buffer classes are actually different depending on the byte order.\\nThe native buffer is \", _jsx(_components.code, {\n        children: \"DirectLongBufferU\"\n      }), \" while the non-native one is\\n\", _jsx(_components.code, {\n        children: \"DirectLongBufferS\"\n      }), \". The main difference between them is the presence of\\nthe \", _jsx(_components.code, {\n        children: \"Bits.swap\"\n      }), \" method.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Looking further into the method, we can see that it delegates directly\\nto \", _jsx(_components.code, {\n        children: \"Long.reverseBytes\"\n      }), \". While its implementation in Java is quite\\ncomplex, one can notice the \", _jsx(_components.code, {\n        children: \"@HotSpotIntrinsicCandidate\"\n      }), \" annotation. The\\nannotation is a signal that at runtime, JIT could replace the method\\nwith pre-prepared assembly code. Adding a set of JVM options,\\n\", _jsx(_components.code, {\n        children: \"-XX:CompileCommand=print,\\\\*OrderBenchmark.sumBytes*\"\n      }), \", to the benchmark\\nallows us to peek at the resulting assembly code to understand how\\nexactly the \", _jsx(_components.code, {\n        children: \"reverseBytes\"\n      }), \" affects the resulting code.\"]\n    }), \"\\n\", _jsxs(\"table\", {\n      children: [_jsxs(\"colgroup\", {\n        children: [_jsx(\"col\", {\n          style: {\n            width: \"50%\"\n          }\n        }), _jsx(\"col\", {\n          style: {\n            width: \"50%\"\n          }\n        })]\n      }), _jsx(\"thead\", {\n        children: _jsxs(\"tr\", {\n          className: \"header\",\n          children: [_jsx(\"th\", {\n            style: {\n              textAlign: \"left\"\n            },\n            children: \"Non-native (Big Endian)\"\n          }), \"\\n\", _jsx(\"th\", {\n            style: {\n              textAlign: \"left\"\n            },\n            children: \"Native (Little Endian)\"\n          })]\n        })\n      }), _jsx(\"tbody\", {\n        children: _jsxs(\"tr\", {\n          className: \"odd\",\n          children: [_jsx(\"td\", {\n            style: {\n              textAlign: \"left\"\n            },\n            children: _jsx(\"pre\", {\n              children: _jsx(_components.pre, {\n                children: _jsxs(_components.code, {\n                  className: \"hljs language-x86asm\",\n                  children: [\"....\\n\", _jsx(_components.span, {\n                    className: \"hljs-symbol\",\n                    children: \"loop:\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10d\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"DWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"rdx\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x14\"\n                  }), \"]\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ecx\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"DWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x8\"\n                  }), \"]\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"                  \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; &lt;- buffer\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"cmp\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ecx\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x16577b\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"jne\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x00007f9d5c277070\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ebx\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"DWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x1c\"\n                  }), \"] \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; &lt;- limit\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"cmp\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11d\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ebx\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"jge\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x00007f9d5c277078\"\n                  }), \"  \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; checkIndex(i)\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"QWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x10\"\n                  }), \"]\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"movsxd\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11d\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"shl\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x3\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"add\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"QWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"] \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; r10 = get(i)\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"bswap\"\n                  }), \"  \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"                 \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; reverseBytes(r10)\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"add\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"rax\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"             \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; sum += r10\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"inc\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11d\"\n                  }), \"                \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; i+=1\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"cmp\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11d\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x8000000\"\n                  }), \"      \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; i &lt; SIZE/8\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"jl\"\n                  }), \"     \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"loop\"\n                  }), \"\\n...\\n\"]\n                })\n              })\n            })\n          }), _jsx(\"td\", {\n            style: {\n              textAlign: \"left\"\n            },\n            children: _jsx(\"pre\", {\n              children: _jsx(_components.pre, {\n                children: _jsxs(_components.code, {\n                  className: \"hljs language-x86asm\",\n                  children: [\"...\\n\", _jsx(_components.span, {\n                    className: \"hljs-symbol\",\n                    children: \"loop:\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11d\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"DWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r8\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x14\"\n                  }), \"] \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; &lt;- buffer\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r9d\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"DWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x1c\"\n                  }), \"] \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; &lt;- limit\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"cmp\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ecx\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r9d\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"jge\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x00007f268c274f57\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; checkIndex(i)\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"QWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11\"\n                  }), \"+\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x10\"\n                  }), \"]\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"movsxd\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ecx\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"shl\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x3\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"add\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"mov\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r11\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"add\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"rbx\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"QWORD\"\n                  }), \" \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"PTR\"\n                  }), \" [\", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"r10\"\n                  }), \"] \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; sum += get(i)\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"inc\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ecx\"\n                  }), \"                 \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; i+=1\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"cmp\"\n                  }), \"    \", _jsx(_components.span, {\n                    className: \"hljs-built_in\",\n                    children: \"ecx\"\n                  }), \",\", _jsx(_components.span, {\n                    className: \"hljs-number\",\n                    children: \"0x8000000\"\n                  }), \"       \", _jsx(_components.span, {\n                    className: \"hljs-comment\",\n                    children: \"; i &lt; SIZE/8\"\n                  }), \"\\n \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"jl\"\n                  }), \"     \", _jsx(_components.span, {\n                    className: \"hljs-keyword\",\n                    children: \"loop\"\n                  }), \"\\n...\\n\"]\n                })\n              })\n            })\n          })]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Comparing the compilations listings of these two implementations, we can\\nnotice that the biggest difference between them is the \", _jsx(_components.code, {\n        children: \"bswap\"\n      }), \"\\ninstruction which is the essence of the \", _jsx(_components.code, {\n        children: \"Bytes.swap\"\n      }), \" method. As\\nexpected, it reverses the byte order every time a long is read from the\\nbuffer.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Reading a gigabyte of memory into longs is an interesting workload, but\\nit‚Äôs not necessarily the one that you‚Äôre likely to encounter in\\nproduction. Endianness can be a useful thing to remember about, but\\nunless working with native libraries or working with massive files, it‚Äôs\\nunlikely to be a concern.\"\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"conclusion\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#conclusion\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Conclusion\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Every non-trivial Java application directly or indirectly uses byte\\nbuffers. On the surface, ByteBuffer is a simple class. It‚Äôs just a\\npointer to a chunk of memory. Nevertheless, even by looking at such a\\nsimple class, you can discover a deep rabbit hole. Even though we‚Äôve\\nonly looked at the tip of the iceberg, I hope that you have a clear idea\\nnow of when you could use a heap buffer, and when you would choose a\\ndirect buffer.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Modern JVM runtimes are complicated environments. While they provide\\nsane defaults, they also present multiple options. The choice is always\\nthere, it‚Äôs up to you to make that choice, but it‚Äôs crucial to be aware\\nof the consequences. Fortunatelly, JVM runtimes also come with a whole\\nlot of various observability tools, JMX metrics, GC logs, profilers, and\\nif you really want it‚Äôs not even that hard to look at the generated\\nassembly code. Using techniques shown in this article, you can make a\\nchoice not for the workload of a guy from the internet, but for \", _jsx(_components.em, {\n        children: \"your\"\n      }), \"\\nworkload, which can result in amazing results in production later. We\\nhave to care more about later sometimes, you know.\"]\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"thank-you-to\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#thank-you-to\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Thank you to\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"Uri Baghin and \", _jsx(_components.a, {\n          href: \"https://twitter.com/ptuls\",\n          children: \"Paul Tune\"\n        }), \" for reviewing\\nthe article.\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"You for reading the article.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"references\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#references\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"References\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://github.com/jvm-profiling-tools/async-profiler/\",\n          children: \"Async Profiler\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://www.youtube.com/watch?v=iwSCtxMbBLI\",\n          children: \"Beyond ByteBuffers by Brian Goetz\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://gceasy.io/\",\n          children: \"GC Easy GC Analyser\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://shipilev.net/jvm/anatomy-quarks/4-tlab-allocation/\",\n          children: \"JVM Anatomy Quark #4: TLAB allocation\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://www.youtube.com/watch?v=DKJ0w30M0vg\",\n          children: \"Netty - One Framework to rule them all by Norman Maurer\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://netty.io/wiki/using-as-a-generic-library.html\",\n          children: \"Netty‚Äôs ByteBuf API\"\n        })\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"discuss-on\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#discuss-on\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Discuss on\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://twitter.com/SerCeMan/status/1328999241541328897\",\n          children: \"Twitter\"\n        })\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{"title":"Indirect Effects of Allocate Direct","description":"Empty","date":"2020-11-18"}},"frontMatter":{"title":"Indirect Effects of Allocate Direct","description":"Empty","date":"2020-11-18"}},"__N_SSG":true}